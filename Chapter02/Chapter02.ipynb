{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "class MyNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, n_nodes, output_size):\n",
    "        super(MyNeuralNet, self).__init__()\n",
    "        self.operationOne = nn.Linear(input_size, n_nodes)\n",
    "        self.operationTwo = nn.Linear(n_nodes, output_size)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.operationOne(x))\n",
    "        x = self.operationTwo(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_network = MyNeuralNet(input_size = 3, n_nodes = 2, output_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-5.0000e+00, -4.9000e+00, -4.8000e+00, -4.7000e+00, -4.6000e+00,\n        -4.5000e+00, -4.4000e+00, -4.3000e+00, -4.2000e+00, -4.1000e+00,\n        -4.0000e+00, -3.9000e+00, -3.8000e+00, -3.7000e+00, -3.6000e+00,\n        -3.5000e+00, -3.4000e+00, -3.3000e+00, -3.2000e+00, -3.1000e+00,\n        -3.0000e+00, -2.9000e+00, -2.8000e+00, -2.7000e+00, -2.6000e+00,\n        -2.5000e+00, -2.4000e+00, -2.3000e+00, -2.2000e+00, -2.1000e+00,\n        -2.0000e+00, -1.9000e+00, -1.8000e+00, -1.7000e+00, -1.6000e+00,\n        -1.5000e+00, -1.4000e+00, -1.3000e+00, -1.2000e+00, -1.1000e+00,\n        -1.0000e+00, -9.0000e-01, -8.0000e-01, -7.0000e-01, -6.0000e-01,\n        -5.0000e-01, -4.0000e-01, -3.0000e-01, -2.0000e-01, -1.0000e-01,\n        -2.9802e-09,  1.0000e-01,  2.0000e-01,  3.0000e-01,  4.0000e-01,\n         5.0000e-01,  6.0000e-01,  7.0000e-01,  8.0000e-01,  9.0000e-01,\n         1.0000e+00,  1.1000e+00,  1.2000e+00,  1.3000e+00,  1.4000e+00,\n         1.5000e+00,  1.6000e+00,  1.7000e+00,  1.8000e+00,  1.9000e+00,\n         2.0000e+00,  2.1000e+00,  2.2000e+00,  2.3000e+00,  2.4000e+00,\n         2.5000e+00,  2.6000e+00,  2.7000e+00,  2.8000e+00,  2.9000e+00,\n         3.0000e+00,  3.1000e+00,  3.2000e+00,  3.3000e+00,  3.4000e+00,\n         3.5000e+00,  3.6000e+00,  3.7000e+00,  3.8000e+00,  3.9000e+00,\n         4.0000e+00,  4.1000e+00,  4.2000e+00,  4.3000e+00,  4.4000e+00,\n         4.5000e+00,  4.6000e+00,  4.7000e+00,  4.8000e+00,  4.9000e+00])\ntensor([[-5.0000e+00],\n        [-4.9000e+00],\n        [-4.8000e+00],\n        [-4.7000e+00],\n        [-4.6000e+00],\n        [-4.5000e+00],\n        [-4.4000e+00],\n        [-4.3000e+00],\n        [-4.2000e+00],\n        [-4.1000e+00],\n        [-4.0000e+00],\n        [-3.9000e+00],\n        [-3.8000e+00],\n        [-3.7000e+00],\n        [-3.6000e+00],\n        [-3.5000e+00],\n        [-3.4000e+00],\n        [-3.3000e+00],\n        [-3.2000e+00],\n        [-3.1000e+00],\n        [-3.0000e+00],\n        [-2.9000e+00],\n        [-2.8000e+00],\n        [-2.7000e+00],\n        [-2.6000e+00],\n        [-2.5000e+00],\n        [-2.4000e+00],\n        [-2.3000e+00],\n        [-2.2000e+00],\n        [-2.1000e+00],\n        [-2.0000e+00],\n        [-1.9000e+00],\n        [-1.8000e+00],\n        [-1.7000e+00],\n        [-1.6000e+00],\n        [-1.5000e+00],\n        [-1.4000e+00],\n        [-1.3000e+00],\n        [-1.2000e+00],\n        [-1.1000e+00],\n        [-1.0000e+00],\n        [-9.0000e-01],\n        [-8.0000e-01],\n        [-7.0000e-01],\n        [-6.0000e-01],\n        [-5.0000e-01],\n        [-4.0000e-01],\n        [-3.0000e-01],\n        [-2.0000e-01],\n        [-1.0000e-01],\n        [-2.9802e-09],\n        [ 1.0000e-01],\n        [ 2.0000e-01],\n        [ 3.0000e-01],\n        [ 4.0000e-01],\n        [ 5.0000e-01],\n        [ 6.0000e-01],\n        [ 7.0000e-01],\n        [ 8.0000e-01],\n        [ 9.0000e-01],\n        [ 1.0000e+00],\n        [ 1.1000e+00],\n        [ 1.2000e+00],\n        [ 1.3000e+00],\n        [ 1.4000e+00],\n        [ 1.5000e+00],\n        [ 1.6000e+00],\n        [ 1.7000e+00],\n        [ 1.8000e+00],\n        [ 1.9000e+00],\n        [ 2.0000e+00],\n        [ 2.1000e+00],\n        [ 2.2000e+00],\n        [ 2.3000e+00],\n        [ 2.4000e+00],\n        [ 2.5000e+00],\n        [ 2.6000e+00],\n        [ 2.7000e+00],\n        [ 2.8000e+00],\n        [ 2.9000e+00],\n        [ 3.0000e+00],\n        [ 3.1000e+00],\n        [ 3.2000e+00],\n        [ 3.3000e+00],\n        [ 3.4000e+00],\n        [ 3.5000e+00],\n        [ 3.6000e+00],\n        [ 3.7000e+00],\n        [ 3.8000e+00],\n        [ 3.9000e+00],\n        [ 4.0000e+00],\n        [ 4.1000e+00],\n        [ 4.2000e+00],\n        [ 4.3000e+00],\n        [ 4.4000e+00],\n        [ 4.5000e+00],\n        [ 4.6000e+00],\n        [ 4.7000e+00],\n        [ 4.8000e+00],\n        [ 4.9000e+00]])\ntensor([ 25.1000,  24.6000,  24.1000,  23.6000,  23.1000,  22.6000,  22.1000,\n         21.6000,  21.1000,  20.6000,  20.1000,  19.6000,  19.1000,  18.6000,\n         18.1000,  17.6000,  17.1000,  16.6000,  16.1000,  15.6000,  15.1000,\n         14.6000,  14.1000,  13.6000,  13.1000,  12.6000,  12.1000,  11.6000,\n         11.1000,  10.6000,  10.1000,   9.6000,   9.1000,   8.6000,   8.1000,\n          7.6000,   7.1000,   6.6000,   6.1000,   5.6000,   5.1000,   4.6000,\n          4.1000,   3.6000,   3.1000,   2.6000,   2.1000,   1.6000,   1.1000,\n          0.6000,   0.1000,  -0.4000,  -0.9000,  -1.4000,  -1.9000,  -2.4000,\n         -2.9000,  -3.4000,  -3.9000,  -4.4000,  -4.9000,  -5.4000,  -5.9000,\n         -6.4000,  -6.9000,  -7.4000,  -7.9000,  -8.4000,  -8.9000,  -9.4000,\n         -9.9000, -10.4000, -10.9000, -11.4000, -11.9000, -12.4000, -12.9000,\n        -13.4000, -13.9000, -14.4000, -14.9000, -15.4000, -15.9000, -16.4000,\n        -16.9000, -17.4000, -17.9000, -18.4000, -18.9000, -19.4000, -19.9000,\n        -20.4000, -20.9000, -21.4000, -21.9000, -22.4000, -22.9000, -23.4000,\n        -23.9000, -24.4000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(-5, 5, 0.1)\n",
    "x1 = x.view(-1, 1)\n",
    "y = -5 * x + 0.1 \n",
    "y1 = y* torch.randn(x.size())\n",
    "\n",
    "print( x)\n",
    "print(x1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "scalar should be 0D",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-91ce6721a727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x/y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\PyTotch\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36madd_scalar\u001b[1;34m(self, tag, scalar_value, global_step, walltime)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mscalar_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         self._get_file_writer().add_summary(\n\u001b[1;32m--> 346\u001b[1;33m             scalar(tag, scalar_value), global_step, walltime)\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_scalars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_scalar_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\PyTotch\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py\u001b[0m in \u001b[0;36mscalar\u001b[1;34m(name, scalar, collections)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m    247\u001b[0m     \u001b[0mscalar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scalar should be 0D'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[0mscalar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mSummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimple_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: scalar should be 0D"
     ]
    }
   ],
   "source": [
    "writer.add_scalar(\"x/y\", x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 1.0564,  0.9115,  0.3953, -1.1420, -0.6362,  0.0538, -0.6254, -0.5420,\n",
       "         0.3533, -0.2004, -1.2982,  0.1754, -1.3318,  0.6317,  2.7839,  0.3484,\n",
       "         0.1859,  0.6615, -0.1924, -2.4078,  0.4499, -0.4666, -0.0809, -0.1233,\n",
       "        -0.8396,  1.0294, -0.0740,  2.0547,  0.1963, -1.2814,  0.0813, -1.3054,\n",
       "        -1.0788, -0.4756,  0.0541, -0.4810, -0.2415,  0.7360,  1.5896, -0.2902,\n",
       "        -2.4846,  1.0368,  0.4812,  0.6129,  0.6217, -1.2466,  1.7905, -1.0581,\n",
       "        -0.4851,  0.2428, -0.4902,  0.2387,  0.5080,  0.2834, -0.1050, -0.8785,\n",
       "         3.0955, -0.1950, -0.0593,  0.9982, -0.0629,  0.4223,  1.3652, -0.0768,\n",
       "        -0.2569, -1.4057, -0.8076, -0.6247, -0.9136, -1.3368,  2.3734,  0.0637,\n",
       "        -2.7124,  0.3056, -0.4983, -0.0493, -0.1138, -0.2634, -0.5495, -0.4333,\n",
       "         0.7022, -0.7491,  1.4151, -0.7105,  1.0171, -0.1307,  1.0909,  0.6550,\n",
       "        -0.2832,  0.2644,  0.7609, -1.3703,  1.0177,  0.5629,  0.3803,  0.9083,\n",
       "        -1.1965, -1.3057, -2.0444, -0.3133])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "torch.randn(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _ in x :\n",
    "    #print(_)\n",
    "    #print(-5 * _)\n",
    "    #print(-5 * _ + 0.1)\n",
    "    #print(-5 * _ + 0.1 * torch.randn(x.size()))    \n",
    "    writer.add_scalar(\"x/y\", _, -5 * _ + 0.1)\n",
    "    #writer.add_scalar(\"x/y\", _)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "first_order_tensor = torch.tensor([1, 2, 3])\n",
    "print(first_order_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(first_order_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(first_order_tensor[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(first_order_tensor[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33],\n",
      "        [21, 22, 23]])\n"
     ]
    }
   ],
   "source": [
    "second_order_tensor = torch.tensor([ [ 11, 22, 33 ],\n",
    " [ 21, 22, 23 ]\n",
    " ])\n",
    "print(second_order_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22)\n"
     ]
    }
   ],
   "source": [
    "print(second_order_tensor[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_order_tensor = torch.tensor(\n",
    "[\n",
    " [\n",
    " [\n",
    " [1111, 1112],\n",
    " [1121, 1122]\n",
    " ],\n",
    " [\n",
    " [1211, 1212],\n",
    " [1221, 1222]\n",
    " ]\n",
    " ],\n",
    " [\n",
    " [\n",
    " [2111, 2112],\n",
    " [2121, 2122]\n",
    " ],\n",
    " [\n",
    " [2211, 2212],\n",
    " [2221, 2222]\n",
    " ]\n",
    " ]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(my_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.tensor([[11, 12, 13], [21, 22, 23]])\n",
    "print(my_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(fourth_order_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8849, 0.2496],\n",
      "        [0.0906, 0.8850],\n",
      "        [0.3370, 0.4994],\n",
      "        [0.2537, 0.1573]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand([4, 2])\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8849, 0.2496, 0.0906, 0.8850],\n",
       "        [0.3370, 0.4994, 0.2537, 0.1573]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.view([2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0420, 0.2747, 0.9238, 0.6606],\n",
       "         [0.8135, 0.1987, 0.3658, 0.7605],\n",
       "         [0.1217, 0.5256, 0.4733, 0.1900],\n",
       "         [0.7616, 0.0601, 0.1716, 0.6475]],\n",
       "\n",
       "        [[0.4079, 0.0604, 0.9344, 0.1486],\n",
       "         [0.8861, 0.7199, 0.5216, 0.0384],\n",
       "         [0.9297, 0.8486, 0.2294, 0.3931],\n",
       "         [0.7904, 0.9229, 0.3076, 0.5926]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand([4, 2, 4])\n",
    "random_tensor.view([2, 4, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0420, 0.2747, 0.9238, 0.6606],\n",
       "         [0.8135, 0.1987, 0.3658, 0.7605],\n",
       "         [0.1217, 0.5256, 0.4733, 0.1900],\n",
       "         [0.7616, 0.0601, 0.1716, 0.6475]],\n",
       "\n",
       "        [[0.4079, 0.0604, 0.9344, 0.1486],\n",
       "         [0.8861, 0.7199, 0.5216, 0.0384],\n",
       "         [0.9297, 0.8486, 0.2294, 0.3931],\n",
       "         [0.7904, 0.9229, 0.3076, 0.5926]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.view([2, -1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5, 3])\n",
    "y = torch.tensor([3, 2])\n",
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15,  6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6667, 1.5000])\n"
     ]
    }
   ],
   "source": [
    "x_float = torch.tensor([5, 3], dtype = torch.float32)\n",
    "y_float = torch.tensor([3, 2], dtype = torch.float32)\n",
    "print(x_float / y_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing our dataset as a PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0.   380.     3.61   3.  ]\n [  1.   660.     3.67   3.  ]\n [  1.   800.     4.     1.  ]\n [  1.   640.     3.19   4.  ]\n [  0.   520.     2.93   4.  ]\n [  1.   760.     3.     2.  ]\n [  1.   560.     2.98   1.  ]\n [  0.   400.     3.08   2.  ]\n [  1.   540.     3.39   3.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "admit_data = np.genfromtxt('admit_status.csv', delimiter = ',', skip_header = 1)\n",
    "print(admit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[  0.0000, 380.0000,   3.6100,   3.0000],\n        [  1.0000, 660.0000,   3.6700,   3.0000],\n        [  1.0000, 800.0000,   4.0000,   1.0000],\n        [  1.0000, 640.0000,   3.1900,   4.0000],\n        [  0.0000, 520.0000,   2.9300,   4.0000],\n        [  1.0000, 760.0000,   3.0000,   2.0000],\n        [  1.0000, 560.0000,   2.9800,   1.0000],\n        [  0.0000, 400.0000,   3.0800,   2.0000],\n        [  1.0000, 540.0000,   3.3900,   3.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "admit_tensor = torch.from_numpy(admit_data)\n",
    "print(admit_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training neural networks in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = admit_tensor[:300, 1:].float()\n",
    "y_train = admit_tensor[:300, 0].float()\n",
    "x_test = admit_tensor[300:, 1:].float()\n",
    "y_test = admit_tensor[300:, 0].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(my_network.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:  0 loss:  tensor(0.8205, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  1 loss:  tensor(0.8196, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  2 loss:  tensor(0.8187, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  3 loss:  tensor(0.8179, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  4 loss:  tensor(0.8170, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  5 loss:  tensor(0.8161, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  6 loss:  tensor(0.8152, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  7 loss:  tensor(0.8143, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  8 loss:  tensor(0.8135, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  9 loss:  tensor(0.8126, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  10 loss:  tensor(0.8118, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  11 loss:  tensor(0.8109, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  12 loss:  tensor(0.8100, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  13 loss:  tensor(0.8092, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  14 loss:  tensor(0.8084, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  15 loss:  tensor(0.8075, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  16 loss:  tensor(0.8067, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  17 loss:  tensor(0.8059, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  18 loss:  tensor(0.8050, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  19 loss:  tensor(0.8042, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  20 loss:  tensor(0.8034, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  21 loss:  tensor(0.8026, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  22 loss:  tensor(0.8018, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  23 loss:  tensor(0.8009, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  24 loss:  tensor(0.8001, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  25 loss:  tensor(0.7993, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  26 loss:  tensor(0.7985, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  27 loss:  tensor(0.7977, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  28 loss:  tensor(0.7970, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  29 loss:  tensor(0.7962, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  30 loss:  tensor(0.7954, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  31 loss:  tensor(0.7946, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  32 loss:  tensor(0.7938, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  33 loss:  tensor(0.7931, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  34 loss:  tensor(0.7923, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  35 loss:  tensor(0.7915, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  36 loss:  tensor(0.7908, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  37 loss:  tensor(0.7900, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  38 loss:  tensor(0.7893, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  39 loss:  tensor(0.7885, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  40 loss:  tensor(0.7878, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  41 loss:  tensor(0.7870, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  42 loss:  tensor(0.7863, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  43 loss:  tensor(0.7856, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  44 loss:  tensor(0.7848, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  45 loss:  tensor(0.7841, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  46 loss:  tensor(0.7834, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  47 loss:  tensor(0.7827, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  48 loss:  tensor(0.7819, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  49 loss:  tensor(0.7812, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  50 loss:  tensor(0.7805, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  51 loss:  tensor(0.7798, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  52 loss:  tensor(0.7791, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  53 loss:  tensor(0.7784, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  54 loss:  tensor(0.7777, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  55 loss:  tensor(0.7770, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  56 loss:  tensor(0.7763, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  57 loss:  tensor(0.7756, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  58 loss:  tensor(0.7749, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  59 loss:  tensor(0.7743, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  60 loss:  tensor(0.7736, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  61 loss:  tensor(0.7729, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  62 loss:  tensor(0.7722, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  63 loss:  tensor(0.7716, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  64 loss:  tensor(0.7709, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  65 loss:  tensor(0.7703, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  66 loss:  tensor(0.7696, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  67 loss:  tensor(0.7689, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  68 loss:  tensor(0.7683, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  69 loss:  tensor(0.7676, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  70 loss:  tensor(0.7670, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  71 loss:  tensor(0.7664, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  72 loss:  tensor(0.7657, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  73 loss:  tensor(0.7651, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  74 loss:  tensor(0.7644, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  75 loss:  tensor(0.7638, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  76 loss:  tensor(0.7632, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  77 loss:  tensor(0.7626, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  78 loss:  tensor(0.7619, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  79 loss:  tensor(0.7613, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  80 loss:  tensor(0.7607, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  81 loss:  tensor(0.7601, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  82 loss:  tensor(0.7595, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  83 loss:  tensor(0.7589, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  84 loss:  tensor(0.7583, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  85 loss:  tensor(0.7577, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  86 loss:  tensor(0.7571, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  87 loss:  tensor(0.7565, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  88 loss:  tensor(0.7559, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  89 loss:  tensor(0.7553, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  90 loss:  tensor(0.7547, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  91 loss:  tensor(0.7541, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  92 loss:  tensor(0.7536, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  93 loss:  tensor(0.7530, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  94 loss:  tensor(0.7524, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  95 loss:  tensor(0.7518, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  96 loss:  tensor(0.7513, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  97 loss:  tensor(0.7507, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  98 loss:  tensor(0.7501, grad_fn=<BinaryCrossEntropyBackward>)\nepoch:  99 loss:  tensor(0.7496, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    y_pred = my_network(x_train)\n",
    "    loss_score = criterion(y_pred, y_train)\n",
    "    print('epoch: ', epoch, 'loss: ', loss_score)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_score.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}